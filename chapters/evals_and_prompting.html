
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Using LLMs &#8212; POLS 4728</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=1f4eb643" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/evals_and_prompting';</script>
    <link rel="icon" href="../_static/favicon_square_very_bold.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Predictive Modeling" href="predictive.html" />
    <link rel="prev" title="Learning" href="learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/ML_logo_simple.svg" class="logo__image only-light" alt="POLS 4728 - Home"/>
    <script>document.write(`<img src="../_static/ML_logo_simple.svg" class="logo__image only-dark" alt="POLS 4728 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course Information</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../schedule.html">Schedule</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="learning.html">Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Using LLMs</a></li>

<li class="toctree-l1"><a class="reference internal" href="predictive.html">Predictive Modeling</a></li>




<li class="toctree-l1"><a class="reference internal" href="linreg.html">Linear Regression</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reference/prelims_and_digressions.html">Preliminaries and Digressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/hugging_face.html">Hugging Face I</a></li>




<li class="toctree-l1"><a class="reference internal" href="../reference/solutions.html">search_exclude: true</a></li>

<li class="toctree-l1"><a class="reference internal" href="../reference/bibliography.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/alexanderthclark/pols4728" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/alexanderthclark/pols4728/issues/new?title=Issue%20on%20page%20%2Fchapters/evals_and_prompting.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/evals_and_prompting.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Using LLMs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Using LLMs</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-using-pre-trained-llms-machine-learning">Is Using Pre-trained LLMs Machine Learning?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work">How LLMs Work</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fancy-autocomplete-and-bias">Fancy Autocomplete and Bias</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-evolution">Prompt Engineering Evolution</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-llm-classifications-for-supervised-tasks">Evaluating LLM Classifications for Supervised Tasks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-mindset-testdriven-ml">1 Evaluation Mindset ≈ Test‑Driven ML</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#microworkflow">1.1 Micro‑workflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-prompts-think-a-b-testing">2 Evaluating Prompts: Think A/B Testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-vs-few-shots-what-does-the-evidence-say">4 Zero vs. Few Shots: What Does the Evidence Say?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="using-llms">
<span id="evals-and-prompting"></span><h1>Using LLMs<a class="headerlink" href="#using-llms" title="Link to this heading">#</a></h1>
<div class="seealso admonition">
<p class="admonition-title">Reading</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices">Claude 4 Prompt Engineering Best Practices</a></p></li>
<li><p><a class="reference external" href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI Prompt Engineering Guide</a></p></li>
</ul>
</div>
<p>LLMs are used in social science research for both classification (sentiment analysis, for example), document scaling, and topic modeling. The term “foundation models” is used to describe such general-purpose models. <span id="id1">[<a class="reference internal" href="../reference/bibliography.html#id38" title="Ingar K. Haaland, Christopher Roth, Stefanie Stantcheva, and Johannes Wohlfart. Understanding economic behavior using open-ended survey data. Journal of Economic Literature, 2025. Forthcoming. URL: https://www.aeaweb.org/articles?id=10.1257/jel.20251780\&amp;from=f.">Haaland <em>et al.</em>, 2025</a>]</span> highlights the use of LLMs to code open-ended data, noting LLMs will “be the preferred choice over most existing text analysis methods for survey researchers.” <span id="id2">[<a class="reference internal" href="../reference/bibliography.html#id31" title="Joseph T Ornstein, Elise N Blasingame, and Jake S Truscott. How to train your stochastic parrot: large language models for political texts. Political Science Research and Methods, 13(2):264–281, 2025.">Ornstein <em>et al.</em>, 2025</a>]</span> notes where LLMs underperform, though the analysis is limited to GPT-4 and GPT-3. Other methods might be preferred when high-quality training data is available or in the case of very large data where LLMs are expensive. What does very large mean? Using GPT-5 through OpenAI’s API, it would cost maybe $5 to classify 10,000 text responses of about 100 words.<a class="footnote-reference brackets" href="#llm-cost" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> These costs scale linearly, so classifying 1,000,000 responses would cost $500. More complicated prompting could triple the cost.<a class="footnote-reference brackets" href="#few-shot" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> One can save costs by switching to a cheaper model like GPT-5 nano, which is 20-25x cheaper than GPT-5, or using classical text analysis methods.</p>
<p>The LLM cost would likely be dwarfed by the general administrative costs of conducting any survey. For example, <span id="id5">[<a class="reference internal" href="../reference/bibliography.html#id47" title="Margaret E Roberts, Brandon M Stewart, Dustin Tingley, Christopher Lucas, Jetson Leder-Luis, Shana Kushner Gadarian, Bethany Albertson, and David G Rand. Structural topic models for open-ended survey responses. American journal of political science, 58(4):1064–1082, 2014.">Roberts <em>et al.</em>, 2014</a>]</span> uses structural topic modeling to analyze open-ended survey responses from the American National Election Survey, which included 2,323 respondents. The LLM cost would be relatively trivial.</p>
<p>While creating and fine-tuning LLMs is beyond our scope, we’ll use them to:</p>
<ul class="simple">
<li><p>Ease into coding</p></li>
<li><p>Explore performance measures for classification tasks</p></li>
<li><p>Practice effective prompting</p></li>
</ul>
<p>If an LLM solves your problem adequately, there’s no need for more complex ML approaches unless the size of the data makes the LLM route too costly.</p>
<section id="is-using-pre-trained-llms-machine-learning">
<h2>Is Using Pre-trained LLMs Machine Learning?<a class="headerlink" href="#is-using-pre-trained-llms-machine-learning" title="Link to this heading">#</a></h2>
<p>This raises an interesting philosophical question, which we might file next to questions like, “Is Katy Perry an Astronaut?”</p>
<p><strong>Traditional ML Classification:</strong></p>
<ul class="simple">
<li><p>You provide labeled data (experience E)</p></li>
<li><p>Train a model on your specific task (T)</p></li>
<li><p>Performance (P) improves with more of your data</p></li>
</ul>
<p><strong>Using Pre-trained LLMs:</strong></p>
<ul class="simple">
<li><p>The model already learned from internet-scale text (someone else’s E)</p></li>
<li><p>You craft prompts to apply its knowledge to your task</p></li>
<li><p>Model parameters do not change as you provide more data.</p></li>
</ul>
<p>So is it machine learning? Yes, by Mitchell’s definition. The learning happened during pre-training, not when you use it. So, using an LLM doesn’t make you a machine learning engineer the same way using a chess engine doesn’t make you an AI researcher. There is one wrinkle: the model’s performance does improve when you provide clearer instructions or examples. An LLM will adapt to your task without changing its underlying knowledge. For practical, research purposes, this distinction doesn’t matter. You’re still solving classification problems, and you still need rigorous evaluation. Whether you trained the model or someone else did, the scientific method remains the same: define your task, measure performance, validate results.</p>
</section>
<section id="how-llms-work">
<h2>How LLMs Work<a class="headerlink" href="#how-llms-work" title="Link to this heading">#</a></h2>
<p><strong>The “Old” Approach (GPT-3.5 Era):</strong></p>
<ul class="simple">
<li><p>“Like a fancy autocomplete,’’ according to Peter Grabowski of Google</p></li>
<li><p>Statistical pattern matching from many examples</p></li>
<li><p>Role prompts (e.g., “You are an MIT mathematician”) shifted probability distributions to improve the chances of the autocomplete being correct</p></li>
<li><p>Hypothesized sweet spot in detail and length of a prompt</p></li>
</ul>
<p><strong>Modern Chain-of-Thought Models:</strong></p>
<ul class="simple">
<li><p>Built-in multi-step reasoning</p></li>
<li><p>Hidden “thinking” processes before output</p></li>
<li><p>Self-selected reasoning approaches</p></li>
<li><p>Role-playing prompts less effective</p></li>
</ul>
<p>In the video below, I ask ChatGPT’s o3 how to get to Carnegie Hall. You can see the thinking process (at 8x speed), where o3 reasons through the intent of my question based on what it already knows about me. ChatGPT 5 Thinking will behave like o3.</p>
<div style="width: 99%; margin: auto;">
  <iframe src="https://www.youtube.com/embed/_tGDS6g63So?si=JU-cZFBjiaZ8bad"
          style="width: 100%; aspect-ratio: 16 / 9; border: 0;"
          allow="accelerometer; autoplay; clipboard-write;
                 encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen>
  </iframe>
</div>
<p>Claude Haiku or ChatGPT 4.5 are more likely to answer “Practice, practice, practice.” This answer is seemingly the best for a sophisticated autocomplete.</p>
<section id="fancy-autocomplete-and-bias">
<h3>Fancy Autocomplete and Bias<a class="headerlink" href="#fancy-autocomplete-and-bias" title="Link to this heading">#</a></h3>
<p>Fancy autocompletes have their drawbacks and these garner a lot of attention. Namely, LLMs can forward whatever bias is in their training data (like any other model). As noted in <span id="id6">[<a class="reference internal" href="../reference/bibliography.html#id42" title="Mohammad Atari, Mona J Xue, Peter S Park, Damián Blasi, and Joseph Henrich. Which humans? OSF Preprints, 2023.">Atari <em>et al.</em>, 2023</a>]</span>, LLMs are biased toward the pyschology of people from WEIRD (Western, Educated, Industrialized, Rich, and Democratic) societies. LLMs exhibit human-like cognitive biases when trying to generate random sequences <span id="id7">[<a class="reference internal" href="../reference/bibliography.html#id43" title="Katherine Van Koevering and Jon Kleinberg. How random is random? evaluating the randomness and humaness of llms' coin flips. arXiv preprint arXiv:2406.00092, 2024.">Van Koevering and Kleinberg, 2024</a>]</span>. If you ask AI for a random number, some models disproportionately choose 42. Claude is especially bad at this, in my own experience. 42 is a salient number because of Douglas Adams’s “The Hitchhiker’s Guide to the Galaxy.” Its fans are overrepresented on the Internet and thus in training data. Similarly, LLMs can reproduce stereotypes. Companies devote enormous resources to mitigating these biases, but it is not a solved problem.</p>
<figure class="align-center" id="id14">
<a class="reference internal image-reference" href="../_images/claudehaiku-refusal-20250603.png"><img alt="../_images/claudehaiku-refusal-20250603.png" src="../_images/claudehaiku-refusal-20250603.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Response from Claude Haiku 3.5</span><a class="headerlink" href="#id14" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id15">
<a class="reference internal image-reference" href="../_images/claude-haiku35-20250603.png"><img alt="../_images/claude-haiku35-20250603.png" src="../_images/claude-haiku35-20250603.png" style="width: 60%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Response from Claude Haiku 3.5</span><a class="headerlink" href="#id15" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="prompt-engineering-evolution">
<h2>Prompt Engineering Evolution<a class="headerlink" href="#prompt-engineering-evolution" title="Link to this heading">#</a></h2>
<p>Prompt engineering has evolved, meaning many of self-annointed gurus on LinkedIn should probably be ignored. And instead of falling into the trap of trying to hit a moving target by stating best practices in the era of GPT-5, we’ll only take the time to mention that prompting strategies, like role priming, that attempted to shift the model to a better probability distribution are no longer important.</p>
<p><strong>Less effective now:</strong></p>
<ul class="simple">
<li><p>Role priming (“You are an expert…”)</p></li>
<li><p>Explicit “think step-by-step” instructions</p></li>
<li><p>Confidence boosting</p></li>
<li><p>Mystical incantations</p></li>
</ul>
<p><strong>Still valuable:</strong></p>
<ul class="simple">
<li><p>Clear problem specification</p></li>
<li><p>Relevant context and constraints</p></li>
<li><p>Examples of desired output format</p></li>
<li><p>Domain-specific information</p></li>
<li><p>Being smarter than the LLM because they still hallucinate</p></li>
</ul>
<p>It used to be emphasized that LLM performance improves if the prompt included an example with the desired output, instead of merely giving instruction. A prompt with one example corresponds to a one-shot prompting strategy and mutatis mutandis for zero-shot and multi-shot. Something I haven’t addressed above is if newer chain-of-thought models still improve with multi-shot prompting strategies. We’ll test this for ourselves shortly.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluating-llm-classifications-for-supervised-tasks">
<h1>Evaluating LLM Classifications for Supervised Tasks<a class="headerlink" href="#evaluating-llm-classifications-for-supervised-tasks" title="Link to this heading">#</a></h1>
<p><span id="id8">[<a class="reference internal" href="../reference/bibliography.html#id44" title="Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. Chatgpt outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences, 120(30):e2305016120, 2023.">Gilardi <em>et al.</em>, 2023</a>]</span> showed that ChatGPT can outperform crowd workers (Mechanical Turk) on text annotation tasks. <span id="id9">[<a class="reference internal" href="../reference/bibliography.html#id45" title="Petter Törnberg. Large language models outperform expert coders and supervised classifiers at annotating political social media messages. Social Science Computer Review, pages 08944393241286471, 2024.">Törnberg, 2024</a>]</span> shows that GPT-4 outperforms even experts in annotating political social media messages. But how do we know this? How do we measure performance? And how do we find the best prompt? Instead of approaching this through prompt engineering principles, we’ll tackle this in a data-driven way by <em>trying stuff and seeing what works best</em>.</p>
<section id="evaluation-mindset-testdriven-ml">
<h2>1 Evaluation Mindset ≈ Test‑Driven ML<a class="headerlink" href="#evaluation-mindset-testdriven-ml" title="Link to this heading">#</a></h2>
<p><strong>Key idea:</strong> treat a <em>prompt + model</em> pair as a <em>hypothesis</em> you must test against a labelled gold set.</p>
<p>Consider Mitchell’s framework: a system learns from experience E with respect to task T and performance measure P. With pre-trained LLMs, we’re in a remarkable situation—we define T through our prompts, but E (the training on internet-scale text) was done by someone else. We still need to rigorously measure P to know if our prompts work.</p>
<section id="microworkflow">
<h3>1.1 Micro‑workflow<a class="headerlink" href="#microworkflow" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Gold set</strong> – hand‑labelled examples (<code class="docutils literal notranslate"><span class="pre">review</span></code>, <code class="docutils literal notranslate"><span class="pre">sentiment</span></code>).</p></li>
<li><p><strong>Metric</strong> – accuracy, F‑1, or task‑specific cost.</p></li>
<li><p><strong>Batch run</strong> – execute the prompt on every row.</p></li>
<li><p><strong>Record</strong> – score, token cost, failure cases → iterate.</p></li>
</ol>
<blockquote>
<div><p>You now have a <strong>unit test for prompts.</strong></p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="evaluating-prompts-think-a-b-testing">
<h2>2 Evaluating Prompts: Think A/B Testing<a class="headerlink" href="#evaluating-prompts-think-a-b-testing" title="Link to this heading">#</a></h2>
<p>When social scientists evaluate survey questions, we test different wordings to see which performs better. Evaluating LLM prompts works the same way—it’s just A/B testing with different prompt templates.</p>
<p>Here’s a minimal evaluation setup using the same tools from your assignments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">google.generativeai</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">genai</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="c1"># Setup (same as your homework)</span>
<span class="n">genai</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">YOUR_KEY</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">genai</span><span class="o">.</span><span class="n">GenerativeModel</span><span class="p">(</span><span class="s2">&quot;gemini-1.5-flash&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_prompt</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run a prompt on test data and measure performance&quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]:</span>
        <span class="c1"># Insert text into your prompt template</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_content</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    
    <span class="c1"># Calculate metrics</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;true_label&#39;</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;true_label&#39;</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
        <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">predictions</span><span class="p">,</span>
        <span class="s1">&#39;confusion_matrix&#39;</span><span class="p">:</span> <span class="n">cm</span>
    <span class="p">}</span>

<span class="c1"># Define prompt templates</span>
<span class="n">ZERO_SHOT_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Classify the sentiment of this review as &#39;positive&#39; or &#39;negative&#39;.</span>
<span class="s2">Review: </span><span class="si">{text}</span>
<span class="s2">Answer:&quot;&quot;&quot;</span>

<span class="n">FEW_SHOT_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Classify sentiment as &#39;positive&#39; or &#39;negative&#39;.</span>

<span class="s2">Review: &quot;Terrible product, waste of money&quot;</span>
<span class="s2">Answer: negative</span>

<span class="s2">Review: &quot;Excellent quality, highly recommend!&quot;</span>
<span class="s2">Answer: positive</span>

<span class="s2">Review: </span><span class="si">{text}</span>
<span class="s2">Answer:&quot;&quot;&quot;</span>

<span class="c1"># A/B test two prompts</span>
<span class="n">zero_shot_results</span> <span class="o">=</span> <span class="n">evaluate_prompt</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">ZERO_SHOT_PROMPT</span><span class="p">)</span>
<span class="n">few_shot_results</span> <span class="o">=</span> <span class="n">evaluate_prompt</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">FEW_SHOT_PROMPT</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zero-shot accuracy: </span><span class="si">{</span><span class="n">zero_shot_results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Few-shot accuracy: </span><span class="si">{</span><span class="n">few_shot_results</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This is exactly how <span id="id10">[<a class="reference internal" href="../reference/bibliography.html#id44" title="Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. Chatgpt outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences, 120(30):e2305016120, 2023.">Gilardi <em>et al.</em>, 2023</a>]</span> determined that ChatGPT beats crowd workers—they tested prompts systematically on labeled data, not by eyeballing a few examples.</p>
<p>The key insight: treat each prompt variant as an experimental condition. Your “treatment” is the prompt wording, and your outcome is classification accuracy.</p>
</section>
<hr class="docutils" />
<section id="zero-vs-few-shots-what-does-the-evidence-say">
<h2>4 Zero vs. Few Shots: What Does the Evidence Say?<a class="headerlink" href="#zero-vs-few-shots-what-does-the-evidence-say" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Study</p></th>
<th class="head"><p>Model(s)</p></th>
<th class="head"><p>Task family</p></th>
<th class="head"><p>Main result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Brown et al. 2020</p></td>
<td><p>GPT‑3</p></td>
<td><p>42 NLP benchmarks</p></td>
<td><p>0‑shot &lt; 1‑shot &lt; 16‑shot (classic few‑shot curve)</p></td>
</tr>
<tr class="row-odd"><td><p>Kojima et al. 2022</p></td>
<td><p>GPT‑3</p></td>
<td><p>Reasoning (GSM‑8K)</p></td>
<td><p>Adding <em>“Let’s think step by step”</em> closes 60 % of gap to few‑shot.</p></td>
</tr>
<tr class="row-even"><td><p>Wei et al. 2022</p></td>
<td><p>PaLM‑540B</p></td>
<td><p>Math, commonsense</p></td>
<td><p>8‑shot CoT boosts accuracy by up to 36 pp over plain few‑shot.</p></td>
</tr>
<tr class="row-odd"><td><p>Liyanage et al. 2024</p></td>
<td><p>GPT‑4</p></td>
<td><p>Twitter stance</p></td>
<td><p><strong>Zero‑shot CoT matched 4‑shot accuracy</strong> (≈ 93 %).</p></td>
</tr>
<tr class="row-even"><td><p>Chen et al. 2024</p></td>
<td><p>GPT‑4</p></td>
<td><p>6 tasks</p></td>
<td><p>Extra demos show diminishing returns after coverage of each label.</p></td>
</tr>
</tbody>
</table>
</div>
<p>The kicker? <span id="id11">[<a class="reference internal" href="../reference/bibliography.html#id44" title="Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. Chatgpt outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences, 120(30):e2305016120, 2023.">Gilardi <em>et al.</em>, 2023</a>]</span> found that ChatGPT beat crowd workers on political annotation tasks—even with zero-shot prompts. No fancy engineering required. But here’s the catch: they only knew this because they measured properly.</p>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<div class="exercise admonition" id="LLM">

<p class="admonition-title"><span class="caption-number">Exercise 1 </span></p>
<section id="exercise-content">
<p>Find a labeled text data set of interest (<a class="reference external" href="https://github.com/Ravihari123/GPT-for-Twitter-Stance-Labeling/blob/main/final_annotated_dataset_355%20records.csv">here is one</a> from <span id="id12">[<a class="reference internal" href="../reference/bibliography.html#id46" title="Chandreen R Liyanage, Ravi Gokani, and Vijay Mago. Gpt-4 as an x data annotator: unraveling its performance on a stance classification task. PloS one, 19(8):e0307741, 2024.">Liyanage <em>et al.</em>, 2024</a>]</span>) with no more than 400 observations. Write two prompts for classification: one with two examples and one with no examples. Classify the entire data set using Gemini 2.5 Pro and then Gemini 2.5 Flash-Lite for a total of four “models.” Compare accuracy across each. You will be provided with an API key and some sample code.</p>
</section>
</div>
<div class="exercise admonition" id="LLM-grimmer">

<p class="admonition-title"><span class="caption-number">Exercise 2 </span></p>
<section id="exercise-content">
<p>Replicate <span id="id13">[<a class="reference internal" href="../reference/bibliography.html#id32" title="Justin Grimmer. A bayesian hierarchical topic model for political texts: measuring expressed agendas in senate press releases. Political analysis, 18(1):1–35, 2010.">Grimmer, 2010</a>]</span> using an LLM. Find the data <a class="reference external" href="https://github.com/lintool/GrimmerSenatePressReleases">here</a>.</p>
</section>
</div>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="llm-cost" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">1</a><span class="fn-bracket">]</span></span>
<p><em>Assumptions.</em> Model = GPT-5 API priced at $1.25 per 1M <strong>input</strong> tokens and $10.00 per 1M <strong>output</strong> tokens. Tokenization rule-of-thumb: <strong>100 tokens ≈ 75 words</strong> ⇒ 100 words ≈ ~130 input tokens. Output kept minimal (label + brief rationale) at ~30 tokens. No few-shot examples; reusable instructions negligible and <strong>no prompt caching</strong> assumed. Per-response cost ≈ (130×1.25×10^{-6} + 30×1×10^{-5} = $4.625×10^{-4}). Totals: <strong>10k</strong> responses ≈ <strong>$4.63</strong> (rounded to <strong>$5</strong>); <strong>1M</strong> responses ≈ <strong>$462.5</strong> (rounded to <strong>$500</strong>). Costs scale linearly with tokens.</p>
</aside>
<aside class="footnote brackets" id="few-shot" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">2</a><span class="fn-bracket">]</span></span>
<p><em>Assumptions.</em> Few-shot, no caching. A prompt includes the 130 input tokens <em>and</em> a 200-token rubric with 500 tokens of examples. This modifies the previous calculation by now using 830 input tokens. We still assume 30 output tokens.  Totals: <strong>10k</strong> responses ≈ <strong>$13.38</strong>; <strong>1M</strong> responses ≈ <strong>$1338.00</strong>.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "alexanderthclark/pols4728",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="predictive.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Predictive Modeling</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Using LLMs</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-using-pre-trained-llms-machine-learning">Is Using Pre-trained LLMs Machine Learning?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-llms-work">How LLMs Work</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fancy-autocomplete-and-bias">Fancy Autocomplete and Bias</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-evolution">Prompt Engineering Evolution</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-llm-classifications-for-supervised-tasks">Evaluating LLM Classifications for Supervised Tasks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-mindset-testdriven-ml">1 Evaluation Mindset ≈ Test‑Driven ML</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#microworkflow">1.1 Micro‑workflow</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-prompts-think-a-b-testing">2 Evaluating Prompts: Think A/B Testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-vs-few-shots-what-does-the-evidence-say">4 Zero vs. Few Shots: What Does the Evidence Say?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alexander Clark, Columbia University
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>